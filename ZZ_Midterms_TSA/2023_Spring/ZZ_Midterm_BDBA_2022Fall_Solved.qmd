---
title: "8_TS_BDBA_2022F_Midterm"
toc: true
toc-location: left
toc-depth: 6
self-contained: true
format: html
editor: visual
params:
  print_sol: true
---

```{r}
library(fpp3)
```

# 0. Import data

```{r}
sp_arrivals <- readr::read_delim("Spain_Arrivals_Monthly.csv", delim = ",") %>% 
            mutate(year = substr(period, 1, 4),
                   month = substr(period, 6, 8),
                   ym = make_yearmonth(year = year, month = month),
                   value = as.numeric(gsub(".", "", value, fixed=TRUE))
                   ) %>% 
            select(ym, value) %>% 
            as_tsibble()
            # mutate(t = gsub(".", "", value, fixed=TRUE))
            
sp_arrivals
```

# 1. Create a time-plot of the series, adjusting the time grid so that it signals the beginning of every year (1 point).

```{r, include=params$print_sol}
#SOLUTION
autoplot(sp_arrivals) +
scale_x_yearmonth(date_breaks = "1 year",
                  date_minor_breaks = "1 year") +
# Flip x-labels by 90 degrees
theme(axis.text.x = element_text(angle = 90))
```

## 1.1 Looking at the timeplot prior to 2020, what is the seasonal period you would expect? (max. 30 words)

```{r, include=params$print_sol}
# There is clearly a pattern that repeats every year. We would therefore expect
# a seasonal period of 1 year
```

# 2. TS Decomposition (2 points)

## 2.1 Perform an X11 Decomposition with default parameters. (0.5 points)

Store the resulting components in a variable called `x11_dcmp`. Then depict the decomposition.

```{r, include=params$print_sol}
x11_dcmp <- sp_arrivals %>%
  model(x11 = X_13ARIMA_SEATS(value ~ x11())) %>%
  components()

autoplot(x11_dcmp) +
  labs(title =
    "Decomposition using X-11.")
```

### 2.1.1 Is the result an additive, multiplicative or other type (mixed) decomposition? (30 words max.) (0.25 points)

```{r, include=params$print_sol}
# The resulting decomposition is a mixed scheme. We can spot this on the top of 
# the graph of th X11 decomposition.
```

## 2.2 Perform an STL decomposition with default arguments (0.5 points)

Store the resulting components in a variable called `STL_defaults`. Then depict the resulting decomposition.

```{r, include=params$print_sol}
STL_defaults <- sp_arrivals %>%
    model(
      STL(value)
      ) %>%
    components()

autoplot(STL_defaults)
```

## 2.3 Which of these two decompositions is more appropriate? Justify briefly (40 words). (0.5 points)

```{r, include=params$print_sol}
# The X11 decomposition is more appropriate because the variance of the remainder 
# component is smaller than that of the seasonal component. Even in the region 
# of the COVID crisis. This is not the case for the STL decomposition.
```

## 2.4 Asjust the parameters of the STL decomposition to improve it. (0.5 points)

```{r, include=params$print_sol}
STL_dcmp_2 <- sp_arrivals %>%
  model(
    STL(value ~ trend(window = 5) + season(window = 5))
    ) %>%
  components()

autoplot(STL_dcmp_2)
```

# 3. Autocorrelation (2 points)

## 3.1 Create an ACF of the seasonal component resulting from the X11 decomposition. Depict 36 lags. (0.66 points)

```{r, include=params$print_sol}
x11_dcmp %>% select(seasonal) %>% ACF(lag_max=36) %>% autoplot()
```

### 3.1.1 Which lags exhibit the strongest positive correlation? Why? (30 words max)

```{r, include=params$print_sol}
# lags 12, 24, 36... the lags that are multiples of the seasonal period (m=13).
```

## 3.2 Create an ACF plot of the entire time series, depicting up to 36 lags: (0.67 points)

```{r, include=params$print_sol}
sp_arrivals %>% ACF(lag_max = 36) %>% autoplot()
```

### 3.2.1 Which lag exhibits the strongest positive correlation? Why? (30-40 words max)

```{r, include=params$print_sol}
# Lag 1 because for short lags and this dataset the effect of the trend dominates 
# seems to dominate over the effect the seasonal + remainder components.
```

## 3.3 Create an ACF plot of the remainder component of the X11 decomposition. Depict 36 lags. (0.67 points)

```{r, include=params$print_sol}
x11_dcmp %>% select(irregular) %>% ACF(lag_max = 36) %>% autoplot()
```

```{r}
STL_dcmp_2 %>% ACF(remainder, lag_max = 36) %>% autoplot()
```


### 3.3.1 Does the remainder component look like white noise? (30 words).

```{r, include=params$print_sol, eval=FALSE}
# No, clearly there is a lot of autocorrelation left in the remainder components.
# The decomposition is unlikely
```

# 4. Cross-validation (2 points)

## 4.1 Create a sub-time series that contains only observations prior to 2020. Call this time series `sp_arrivals_2019` (0.25 points).

```{r, include=params$print_sol}
sp_arrivals_2019 <- sp_arrivals %>% filter(year(ym) <= 2019)

sp_arrivals_2019
```

## 4.2 Using `sp_arrivals_2019`, create a series of training datasets for cross-validation fulfilling the following (0.25 points).

-   The smallest dataset contains all the observations up to and including Oct 2017.
-   The datasets increase one observation at a time

```{r, include=params$print_sol}
init_size <- sp_arrivals_2019 %>% filter(ym <= yearmonth("2017 Oct")) %>% nrow()

sp_arrivals_2019_cv <- sp_arrivals_2019 %>% 
                  stretch_tsibble(.init = init_size, .step = 1)

sp_arrivals_2019_cv
```

## 4.3 Fit the following models to each of the training datasets (0.5 points)

-   Mean model
-   Naive model
-   Drift model
-   Seasonal naive model
-   Decomposition model using:
    -   The STL decomposition with-non default values defined in 2.4. Alternatively you may use the standard STL arguments.
    -   The drift component for the seasonally adjusted component
    -   The SMAIVE component for the seasonal component

```{r, include=params$print_sol}
fit_cv <- sp_arrivals_2019_cv %>% model(
    mean=MEAN(value),
    naive=NAIVE(value),
    snaive=SNAIVE(value),
    drift=RW(value ~ drift()),
    dcmp=decomposition_model(
              STL(value ~ trend(window = 5) + season(window = 5)),
              RW(season_adjust ~ drift())
          )
  
)

fit_cv
```

## 4.4 Perform forecasts of up to one seasonal period. Then compute the error metrics **for each of the forecast horizons and models** using `accuracy()`. Order the models by increasing RMSE for each forecast horizon. (0.75 points)

```{r, include=params$print_sol}
fc_cv <- fit_cv %>% 
          forecast(h=12) %>%
          group_by(.id, .model) %>%
          mutate(
            h = row_number()
          ) %>%
          ungroup() %>% 
          as_fable(response = "value", distribution = value)

summary_cv_h <- 
  fc_cv %>% 
  accuracy(sp_arrivals_2019, by=c("h", ".model")) %>% 
  arrange(h, RMSE)
```

### 4.4.1 Filter the table above so that only the best 3 models for each forecast horizon are shown

```{r, include=params$print_sol}
summary_cv_h %>%
  group_by(h) %>% 
  mutate(row = row_number()) %>% 
  filter(row <= 3) %>% 
  select(-row)
```

## 4.5 Compute the average RMSE of each model for all the forecast horizons (0.75 points).

```{r, include=params$print_sol}
summary_cv <- 
  fc_cv %>% 
  accuracy(sp_arrivals_2019, by=c(".model")) %>% 
  arrange(RMSE)

summary_cv
```

### 4.5.1 Which is the best performing model on average in terms of RMSE? (30 words)

------------------------------------------------------------------------

Your answer goes here

------------------------------------------------------------------------

# 5. Single train-test split (2.5 points)

## 5.1 Fit a seasonal naive model to `sp_arrivals_2019`. Perform forecasts of up to one year ahead. (0.5 points)

```{r, invlude=params$print_sol}
fit <- 
  sp_arrivals_2019 %>% 
  model(
    snaive = SNAIVE(value)
  )

fc <- fit %>% forecast(h=12)

fc
```

## 5.2 Compute the average RMSE of the previous forecasts (averaged over all forecast horizons) (0.5 points)

```{r, invlude=params$print_sol}
summary <- fc %>% accuracy(sp_arrivals)

summary
```

## 5.3 Cumpute the difference between the average RMSE of the SNAIVE model on these forecasts with the average (over all horizons) RMSE of the SNAIVE of the cross-validated metrics of point 4.5. (0.75 points)

```{r, invlude=params$print_sol}
(summary %>% pull(RMSE)) - (summary_cv %>% filter(.model=="snaive") %>% pull(RMSE))
```

### 5.3.1 What are the units of this result? (20 words max)

```{r, invlude=params$print_sol}
# The units are tourists, the same units of the original time series.
```

### 5.3.2 How would you interpret this result? (75 words max)

```{r, invlude=params$print_sol}
# The RMSE of the SNAIVE model beyond 2019 is much greater than before because
# of the COVID crisis, which completely changed the dynamics of the time series.

# Cross validation does not protect against abrupt external changes.
```

## 5.4 Depict the forecasts provided by the SNAIVE model together with the actual values of the time series beyond 2020 (0.75 points)

```{r, include=params$print_sol}
fc %>%
  autoplot(sp_arrivals)
```
