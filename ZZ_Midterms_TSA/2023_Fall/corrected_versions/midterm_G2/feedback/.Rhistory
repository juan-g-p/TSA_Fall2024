breaks = seq(-1, 10, by = 1)
data <- tibble(
x = seq(-0.999, 9, by = 0.01),
y = log(1+x),
line_x = c(-0.75, 0.75, rep(NA, length.out = 998)),
line_y = c(-0.75, 0.75, rep(NA, length.out = 998))
)
p2 <-
ggplot(data) +
geom_line(aes(x=x, y=y)) +
geom_line(aes(x=line_x, y=line_y), color="red", linetype="dashed") +
geom_point(aes(x=0, y=0), color="red") +
scale_x_continuous(
breaks = breaks,
minor_breaks = breaks,
limits = c(-1, max(data$x)) # Set the x-axis limits
) +
ggtitle("y = log(1+x)") +
annotate("text", x = 0.5, y = -2, label = TeX(r"( $y \rightarrow -\infty$ \n if $x \rightarrow -1$)"), parse = TRUE) +
geom_segment(aes(x = -0.2, y = -2.5, xend = -0.8, yend = -5),
arrow = arrow(type = "closed", length = unit(0.1, "inches")),
color = "black", size=0.01) +
geom_vline(xintercept = -1, linetype="dashed",
color = "blue", size=0.5)
aus_production %>%
autoplot(Gas)
library(fpp3)
library(patchwork)
library(latex2exp)
#| echo: false
#| warning: false
breaks = seq(-1, 10)
data <- tibble(
x = seq(0.001, 10, 0.01),
y = log(x),
line_x = c(0.25, 1.75, rep(NA, 998)),
line_y = c(-0.75, 0.75, rep(NA, 998))
)
p1 <-
ggplot(data) +
geom_line(aes(x=x, y=y)) +
geom_line(aes(x=line_x, y=line_y), color="red", linetype="dashed") +
geom_point(aes(x=1, y=0), color="red") +
scale_x_continuous(breaks = seq(-5, 10),
minor_breaks = seq(-5, 10),
limits = c(-1, max(data$x)) # Set the x-axis limits
) +
ggtitle("y = log(x)") +
geom_vline(xintercept = 0, linetype="dashed",
color = "blue", size=0.5)  +
annotate("text", x = 1.8, y = -2, label = TeX(r"( $y \rightarrow -\infty$ \n if $x \rightarrow 0$)"), parse = TRUE) +
geom_segment(aes(x = 1.2, y = -2.5, xend = 0.2, yend = -5),
arrow = arrow(type = "closed", length = unit(0.1, "inches")),
color = "black", size=0.01)
#| echo: false
#| warning: false
#| fig.width: 8
#| fig.height: 4
library(ggplot2)
library(tibble) # Make sure you load the tibble package
library(latex2exp)
breaks = seq(-1, 10, by = 1)
data <- tibble(
x = seq(-0.999, 9, by = 0.01),
y = log(1+x),
line_x = c(-0.75, 0.75, rep(NA, length.out = 998)),
line_y = c(-0.75, 0.75, rep(NA, length.out = 998))
)
p2 <-
ggplot(data) +
geom_line(aes(x=x, y=y)) +
geom_line(aes(x=line_x, y=line_y), color="red", linetype="dashed") +
geom_point(aes(x=0, y=0), color="red") +
scale_x_continuous(
breaks = breaks,
minor_breaks = breaks,
limits = c(-1, max(data$x)) # Set the x-axis limits
) +
ggtitle("y = log(1+x)") +
annotate("text", x = 0.5, y = -2, label = TeX(r"( $y \rightarrow -\infty$ \n if $x \rightarrow -1$)"), parse = TRUE) +
geom_segment(aes(x = -0.2, y = -2.5, xend = -0.8, yend = -5),
arrow = arrow(type = "closed", length = unit(0.1, "inches")),
color = "black", size=0.01) +
geom_vline(xintercept = -1, linetype="dashed",
color = "blue", size=0.5)
p1 / p2
canadian_gas %>%
autoplot(Volume) +
labs(
x = "Year", y = "Gas production (billion cubic meters)",
title = "Monthly Canadian gas production"
)
aus_production %>%
autoplot(Gas)
aus_production %>%
autoplot(Gas) +
scale_x_yearquarter(
breaks = "4 years",
minur_breaks = "1 year"
)
aus_production %>%
autoplot(Gas) +
scale_x_yearquarter(
breaks = "4 years",
minor_breaks = "1 year"
)
aus_production %>%
autoplot(Gas) +
scale_x_yearquarter(
breaks = "8 years",
minor_breaks = "1 year"
)
aus_production %>%
autoplot(Gas) +
scale_x_yearquarter(
breaks = "10 years",
minor_breaks = "1 year"
)
lambda <- aus_production %>%
features(Gas, features = guerrero) %>%
pull(lambda_guerrero)
lambda
aus_production %>%
autoplot(box_cox(Gas, lambda))
aus_production %>%
autoplot(box_cox(Gas, lambda)) +
scale_x_yearquarter(
breaks = "10 years",
minor_breaks = "1 year"
)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
library(fpp3)
pedestrians_mod <- pedestrian %>%
filter(Sensor == "Southern Cross Station" | Sensor == "Bourke Street Mall (North)") %>%
group_by()
library(fpp3)
pedestrians_mod <- pedestrian %>%
filter(Sensor == "Southern Cross Station" | Sensor == "Bourke Street Mall (North)") %>%
group_by()
pedestrians_mod %>% autoplot() %>%
scale_x_date(date_breaks = '5 weeks', minor_breaks = '1 week') +
theme(axis.text.x = element_text(angle = 45))
## YOUR CODE GOES HERE
scs_pedestrians %>%
autoplot() +
scale_x_date(
breaks = "5 weeks",
minor_breaks = "1 week"
) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
## YOUR CODE GOES HERE
scs_pedestrians %>%
autoplot() +
scale_x_date(
breaks = "5 weeks",
minor_breaks = "1 week"
) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
library(fpp3)
## YOUR CODE GOES HERE
pedestrian <-
# Date %>%
index_by(week = yearweek(time_stamp)) %>%
summarise(
average_NO2 = mean(pedestrian, na.rm = TRUE),
) %>%
mutate(
ym = yearmonth(week)
) %>%
filter(
ym >= yearmonth("2016-07-01"),
ym < yearmonth("2016-10-25")
)
scs_pedestrians <-
read.csv(file.choose()) %>%
mutate(Date = as.Date(Date)) %>%
as_tsibble(index=Date)
scs_pedestrians <-
read.csv(file.choose()) %>%
mutate(Date = as.Date(Date)) %>%
as_tsibble(index=Date)
scs_pedestrians <-
read.csv(file.choose()) %>%
mutate(Date = as.Date(Date)) %>%
as_tsibble(index=Date)
scs_pedestrians
## YOUR CODE GOES HERE
scs_pedestrians %>%
autoplot() +
scale_x_date(
breaks = "5 weeks",
minor_breaks = "1 week"
) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
## DO NOT CREATE ADDITIONAL CODE SNIPPETS, KEEP EVERYTHING IN A SINGLE SNIPPET.
library(fpp3)
test_years = 4
train <- hh_budget %>%
filter(Year <= max(Year) - test_years)
test <- hh_budget %>%
filter(Year > max(Year) - test_years)
# Check dimensions
(nrow(train) + nrow(test)) == nrow(hh_budget)
# NOTE: other functions for dimension checking:
# nrow(), ncol(), dim(), length()
library(fpp3)
library(patchwork)
aus_economy <- global_economy %>%
filter(Code == "AUS") %>%
mutate(Pop = Population / 1e6)
betas = seq(0, 1, 0.01)
df <-
aus_economy %>%
as_tibble() %>%
mutate(Pop = Population / 1e6) %>%
select(Year, Pop)
n = nrow(df)
y = df$Pop
for (beta in betas) {
# alpha = max(beta, 1*beta)
alpha = 0.4
# alpha = min(0.4, 3.5*beta)
l = numeric(n)
b = numeric(n)
yhat = numeric(n)
l_0 = y[1]
b_0 = y[2] - y[1]
# First iteration in terms of initial estimates (alpha = 0.1)
l[1] = alpha*y[1] + (1-alpha)*(l_0 + b_0)
b[1] = beta*(l[1] - l_0)  + (1-beta)*(b_0)
yhat[1] = l_0 + b_0
# Compute fitted values (alpha = 0.1)
for (i in seq(2, nrow(df))) {
l[i] = alpha*y[i] + (1-alpha)*(l[i-1] + b[i-1])
b[i] = beta*(l[i]-l[i-1]) + (1-beta)*b[i-1]
yhat[i] = l[i-1] + b[i-1]
}
df[[paste0("l_" , beta)]] = l
df[[paste0("b_" , beta)]] = b
df[[paste0("y_" , beta)]] = yhat
}
df <-
df %>%
pivot_longer(
cols = l_0:y_1,
names_to = "var",
values_to = "value"
) %>%
mutate(
beta = sapply(strsplit(var, "_"), `[`, 2),
beta = as.numeric(beta)
) %>%
arrange(beta, var, Year)
library(plotly)
library(stringr)
df_data <-
aus_economy %>%
as_tibble() %>%
select(Year, Pop) %>%
mutate(value = Pop)
fig <-
df %>%
filter(str_starts(var, "y")) %>%
plot_ly(
x = ~Year,
y = ~value,
frame = ~beta,
type = "scatter",
mode = "lines",
name = "fitted"
) %>%
add_lines(x = df_data$Year,
y = df_data$Pop,
inherit = FALSE,
line = list(
width = 1,
color = "red",
dash = "dot"
),
name = "data"
)
fig %>% animation_opts(frame = 25, redraw = FALSE)
aus_economy <- global_economy %>%
filter(Code == "AUS") %>%
mutate(Pop = Population / 1e6)
autoplot(aus_economy, Pop) +
labs(y = "Millions", title = "Australian population")
fit <- aus_economy %>%
model(
AAN = ETS(Pop ~ error("A") + trend("A") + season("N"))
)
fit
tidy(fit)
fitted_vals <-
fit %>%
augment()
resid <-  fitted_vals$.innov
# Sum of squared residuals
SSE <- sum(resid^2)
SSE
fc <-
fit %>%
forecast(h = 10)
fc %>% autoplot(aus_economy, level = NULL) +
labs(title = "Australian population",
y = "Millions") +
guides(colour = guide_legend(title = "Forecast"))
holts_components <-
fit %>%
components()
holts_components
# Depict the components
holts_components %>% autoplot()
# Use the equation for the fitted values
holts_components <-
holts_components %>%
mutate(
.fitted = lag(level) + lag(slope) # Equation for the fitted vals
)
# Vector of fitted values computed using augment
fitted_augment <-
fit %>%
augment() %>%
pull(.fitted)
# Vector of fitted values computed using the components() and the equation
fitted_components <-
holts_components %>%
pull(.fitted)
# Remove NAs
fitted_components <-  fitted_components[!is.na(fitted_components)]
all.equal(fitted_augment, fitted_components)
fit_damped_1 <-
aus_economy %>%
model(
holts = ETS(Pop ~ error("A") + trend("A") + season("N")),
# Damping parameter explicitly set to 0.9
damped_holts = ETS(Pop ~ error("A") + trend("Ad", phi = 0.9) + season("N"))
)
fc_damped_1 <-
fit_damped_1 %>%
forecast(h = 15)
fc_damped_1 %>%
autoplot(aus_economy, level = NULL) +
labs(title = "Australian population",
y = "Millions") +
guides(colour = guide_legend(title = "Forecast"))
fc_damped_1 %>%
as_tibble() %>%
select(Year, .model, .mean) %>%
pivot_wider(values_from = c(`.mean`), names_from = c(`.model`))
fit_damped_2 <-
aus_economy %>%
model(
holts = ETS(Pop ~ error("A") + trend("A") + season("N")),
# Specify a grid of values c(0.8, 0.95) for phi
damped_holts = ETS(Pop ~ error("A") +
trend("Ad", phi = NULL, phi_range=c(0.8, 0.95)) +
season("N")
)
)
tidy(fit_damped_2)
fc_damped_2 <-
fit_damped_2 %>%
forecast(h = 15)
fc_damped_2 %>%
autoplot(aus_economy, level = NULL) +
labs(title = "Australian population",
y = "Millions") +
guides(colour = guide_legend(title = "Forecast"))
fit_damped_3 <-
aus_economy %>%
model(
holts = ETS(Pop ~ error("A") + trend("A") + season("N")),
damped_holts = ETS(Pop ~ error("A") + trend("Ad") + season("N"))
)
tidy(fit_damped_3)
fit_damped_3 <-
fit_damped_3 %>%
forecast(h = 15)
fit_damped_3 %>%
autoplot(aus_economy, level = NULL) +
labs(title = "Australian population",
y = "Millions") +
guides(colour = guide_legend(title = "Forecast"))
# Convert time series object to tsibble object for compatibility with fable methods and tools
www_usage <- as_tsibble(WWWusage)
# Plot the data
www_usage %>%
autoplot(value) +
labs(x="Minute", y="Number of users",
title = "Internet usage per minute")
fit <-
www_usage %>%
model(
ses = ETS(value ~ error("A") + trend("N") + season("N")),
holts = ETS(value ~ error("A") + trend("A") + season("N")),
damped_holts = ETS(value ~ error("A") + trend("Ad") + season("N"))
)
fit
# Fitted values fr all models
fitted_vals <-
fit %>%
augment()
# Overcview of residuals for Holts model
fit %>%
select(holts) %>%
gg_tsresiduals()
# qq-plot and box-plot for Holts model
model_vals <-
fitted_vals %>%
filter(.model == "holts")
# Generate qq_plot
p1 <- ggplot(model_vals, aes(sample = .innov))
p1 <- p1 + stat_qq() + stat_qq_line()
# Generate box-plot
p2 <- ggplot(data = model_vals, aes(y = .innov)) +
geom_boxplot(fill="light blue", alpha = 0.7) +
stat_summary(aes(x=0), fun="mean", colour= "red") # Include the mean
p1 + p2
# Small bias. Could be corrected subtracting it from forecasts
# It is probably negligible compared to the magnitude of what we are trying
# to forecast.
fitted_vals %>%
filter(.model == "holts") %>%
pull(.innov) %>%
mean()
# Damped holt model
fit %>%
select(damped_holts) %>%
gg_tsresiduals()
model_vals <-
fitted_vals %>%
filter(.model == "damped_holts")
# Generate qq_plot
p1 <- ggplot(model_vals, aes(sample = .innov))
p1 <- p1 + stat_qq() + stat_qq_line()
# Generate box-plot
p2 <- ggplot(data = model_vals, aes(y = .innov)) +
geom_boxplot(fill="light blue", alpha = 0.7) +
stat_summary(aes(x=0), fun="mean", colour= "red") # Include the mean
p1 + p2
# Bigger bias than holts model. Probably still negligible against what we are
# trying to forecast.
# Nonetheless, it could be corrected
fitted_vals %>%
filter(.model == "damped_holts") %>%
pull(.innov) %>%
mean()
fc <-
fit %>%
forecast(h=10)
fc %>%
autoplot(www_usage, level=FALSE)
fc %>%
filter(.model == "damped_holts") %>%
autoplot(www_usage)
# Convert time series object to tsibble object for compatibility with fable methods and tools
www_usage <- as_tsibble(WWWusage)
# Plot the data
www_usage %>%
autoplot(value) +
labs(x="Minute", y="Number of users",
title = "Internet usage per minute")
www_usage_cv <-
www_usage %>%
stretch_tsibble(.init = 10, .step=1)
# Examine the table created
www_usage_cv
# Examine the number of datasets created
www_usage_cv %>% pull(.id) %>% max()
fit_cv <-
www_usage_cv %>%
model(
SES = ETS(value ~ error("A") + trend("N") + season("N")),
Holt = ETS(value ~ error("A") + trend("A") + season("N")),
Damped = ETS(value ~ error("A") + trend("Ad") + season("N"))
)
fit_cv
fc_cv <-
fit_cv %>%
forecast(h=1)
fc_cv %>%
accuracy(www_usage) %>%
select(.model, MAE, RMSE)
fc_cv <-
fit_cv %>%
forecast(h=10)
fc_cv %>%
accuracy(www_usage) %>%
select(.model, MAE, RMSE)
fit <-
www_usage %>%
model(
Damped = ETS(value ~ error("A") + trend("Ad") + season("N"))
)
tidy(fit)
#Finally let us perform and depict forecasts:
fit %>%
forecast(h = 10) %>%
autoplot(www_usage) +
labs(x="Minute", y="Number of users",
title = "Internet usage per minute")
#Finally let us perform and depict forecasts:
fit %>%
forecast(h = 10) %>%
autoplot(www_usage) +
labs(x="Minute", y="Number of users",
title = "Internet usage per minute")
