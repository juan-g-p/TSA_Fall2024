---
title: "asgmt1_tsgraphs"
format: html
editor: visual
params:
  print_sol: false
toc: true
toc-location: left
toc-depth: 6
self-contained: true
---

# Libraries

```{r}
library(fpp3)
```

# Instructions

-   This notebook contains a series of exercises **to be solved individually by each student**.

-   When answering the questions please **stick to the questions asked and respect the limit to the number of words** (use an online word counter or your text processor of choice).

-   **Answering more than what is asked for in the question will not provide additional points**. More often than not, it actually leads to a worse grade since the additional info provided usually shows a lack of understanding of some concepts on the student's part.

-   **Before delivering the assignment** **make sure you are delivering executable code**. To do this (dedicated video on the appendix RStudio Basics)

    1.  Delete all variables in your environment.
    2.  Restart your R Session.
    3.  Click on Run -\> Run all

    -   **IMPORTANT:** if the code you deliver is not executable from beginning to end, you will be somewhat penalized in your assignment (depending on the severity of the issue). So please bear this in mind. At university level the least expected is that you deliver executable code.

# 1. (3.3 points)

The PBS dataset included in fpp3 contains Monthly Medicare Australia prescription data. Run `?PBS` on the console for further info.

We would like to focus on the prescriptions with ATC (Anatomical Therapeutic Chemical Index level 2) equal to H02. This group corresponds to corticosteroids for systemic use.

```{r}
PBS_h02 <- PBS %>%
  filter(ATC2 == "H02") %>%
  select(ATC2, Month, Cost, everything()) %>%
  arrange(Month)
```

1.  As you can see, after filtering for `ATC2 == H02` there are 4 entries per month corresponding to different combinations of the columns Concession and Type. We would like to add the Cost associated to those 4 entries for every month, to obtain a time series of the total cost per month. Use `index_by()` and `summarise()` to get the total cost per month **(1 point)**

```{r}
# Your code goes here
PBS_h02_1 <- PBS_h02 %>%
  index_by(month = yearmonth(Month)) %>%
  summarise(
    total_cost = sum(Cost)
  )

PBS_h02_1
```

2.  Create and interpret a time-plot with sufficient resolution to visually identify the seasonality **(0.8 points)**

```{r}
# Your code goes here
autoplot(PBS_h02_1)
```

------------------------------------------------------------------------

**Your interpretation goes here** (max 50. words)

A positive linear relationship can be analyzed through time. Seasonal trends can be identified as total costs at the beginning of each year are low and increase as time goes by. No specific cyclical behavior can be seen as the trend is constantly increasing over time.

------------------------------------------------------------------------

3.  Create and interpret a seasonal plot and a seasonal subseries plots to identify the evolution of the seasonal component. **(0.8 points)**

```{r}
# Your code goes here
#Seasonal Plot
PBS_h02_1 %>%
  gg_season(total_cost, labels = "right") + 
  labs(y = "Total Cost",
       title = "Total Cost per Month") + 
  theme(legend.position = "bottom")


#Seasonal Subseries
PBS_h02_1 %>%
  gg_subseries(total_cost) +
  labs(
    y = "Total Cost",
    title = "Total Cost per Month",
  ) + theme(legend.position = "bottom")

```

------------------------------------------------------------------------

**Your interpretation goes here** (max 50. words)

In January (of all years) the total costs are higher. In February the total costs fall and start to increase as the year goes by. It can also be seen that as the years goes by total costs increase. Total costs in December are equally as high as in January.

------------------------------------------------------------------------

4.  Create and interpret ACF plots and lag plots to identify the seasoanlity **(0.8 points)**

```{r}
# Your code goes here
#ACF Plots
PBS_h02_1 %>%
  ACF(lag_max = 24) %>%
  autoplot()

#Lag Plots
PBS_h02_1 %>%
  gg_lag(y = total_cost, geom = "point", lags = 1:12)
```

------------------------------------------------------------------------

**Your interpretation goes here** (max 30. words)

Both plots show that there is a yearly seasonality after 12 lags. The ACF shows a spike every 12 months. The lag plot 12 also shows the highest similarity with the variable.

------------------------------------------------------------------------

# 2. (3.3 points)

Use the following graph functions: autoplot(), gg_season(), gg_subseries(), gg_lag(), ACF() and explore features of the time series Total Private from the dataset us_employment (loaded with fpp3) (3.3 points)

```{r}
total_private <- us_employment %>%
  filter(Title == "Total Private")

total_private
```

-   2.1 Generate a timeplot that has major ticks every ten years and minor ticks every year **(1.1 points)**

```{r}
# Your code goes here
total_private %>%
  autoplot() +
  scale_x_yearmonth(breaks = "10 years",
                     minor_breaks = "1 year")  +
  theme(axis.text.x = element_text(angle = 90))


```

-   2.2 Use `gg_season()` and `gg_subseries()` to examine the evolution of the seasonal components over time (period of 1 year). That is, generate the graphs and interpret them **(1.1 points)**

```{r}
# Your code goes here
total_private %>%
  gg_season(Employed, labels = "right") + 
  labs(y = "Employed",
       title = "Employment Levels for Different Seasons") + 
  theme(legend.position = "bottom")


#Seasonal Subseries
total_private %>%
  gg_subseries(Employed) +
  labs(y = "Employed",
       title = "Employment Levels for Different Seasons") + 
  theme(legend.position = "bottom")
```

------------------------------------------------------------------------

**Your interpretation goes here** (Max 50. words)

Using this data, there is a strong positive relationship as time goes by. In the time series this can be observed through an almost straight line. In the seasonal and subseries plot, it can be seen by data increasing through time in always possible. Â 

------------------------------------------------------------------------

-   2.3 Use `gg_lag()` and `ACF()` to examine the autocorrelation of the series. Again, generate the graphs and interpret them **(1.1 points)**

```{r}
# Your code goes here
#ACF Plots
total_private %>%
  ACF(Employed) %>%
  autoplot()

#Lag Plots
total_private %>%
  gg_lag(y = Employed, geom = "point", lags = 1:12)
```

------------------------------------------------------------------------

**Your interpretation goes here** (Max 50. words)

A strong positive trend can be analyzed throughout time as all of the lags show a strong positive correlation between the plots and variable. The ACF is slight decreasing through time meaning that strength of the relationship is decaying. No other trends can be confirmed using visual representations.

------------------------------------------------------------------------

# 3. Stock prices (3.4/10 points)

The GAFA stock prices dataset in the ffp3 package contains historical stock prices from 2014-2018 for Google, Amazon, Facebook and Apple. All prices are in \$USD

## 3.1 Use `group_by()` in combination with `filter()` and `max()` to find what days correspond to the peak closing price for each of the four stocks in the dataset `gafa_stock` (**0.5 points**)

```{r}
# Your code goes here
stocks <- gafa_stock %>% as_tibble() %>% group_by(Symbol) %>% summarise(hc = max(Close))

stocks

```

## 3.2 Amazon Stock Prices

The following code computes the daily changes in Amazon closing stock prices from 2018 onwards:

```{r}
damzn <- gafa_stock %>%
  filter(Symbol == "AMZN", year(Date) >= 2018) %>%
  mutate(trading_day = row_number()) %>%
  update_tsibble(index = trading_day, regular = TRUE) %>%
  mutate(diff = difference(Close))
```

-   3.2.1 Why does the code above re-index the tsibble? Hint: run `?update_tsibble()` on the console to access the documentation and read about the argument regular (**0.5 points**)

------------------------------------------------------------------------

**Your answer goes here (max 30 words)**

It is necessary to re-index the data since it doesn\'t take into consideration
weekends. It only considers the weekdays which is why a new index of trading days in necessary (showing the time interval).

------------------------------------------------------------------------

-   3.2.2 Use the function `lag()` to compute an additional column `diff2` that should be equal to the column `diff`. Hint: you need to compute the first lag of the variable Close to do this. (**0.5 points**)

```{r}
# Your code goes here
damzn[[paste0("diff2")]] = lag(damzn$diff, 1)
```

-   3.2.3 Create a time plot of the closing prices and a time plot of the differences. These plots must have major ticks every 20 trading days and minor ticks every 10 trading days (**0.5 points**)

```{r}
# Your code goes here
#Closing Prices
major_ticks_seq = seq(0, max(damzn$trading_day), 20)
major_ticks_seq

minor_ticks_seq = seq(0, max(damzn$trading_day), 10)
minor_ticks_seq

damzn %>%
  autoplot(damzn$Close) +
  scale_x_continuous(breaks = major_ticks_seq,
                     minor_breaks = minor_ticks_seq)

#Differences
damzn %>%
  autoplot(damzn$diff) +
  scale_x_continuous(breaks = major_ticks_seq,
                     minor_breaks = minor_ticks_seq)


```

-   3.2.4 Create the correlogram of the closing prices and of the differences in prices using the ACF() and autoplot() functions. Depict 100 lags (look at the argument lag_max). **(0.5 points)**

```{r}
# Your code goes here
#Closing Prices
damzn %>%
  ACF(damzn$Close, lag_max = 100) %>%
  autoplot()

#Differences
damzn %>%
  ACF(damzn$diff, lag_max = 100) %>%
  autoplot()
```

-   3.2.5 Do the differences in the stock look like white noise? **(0.45 points)**.

------------------------------------------------------------------------

**Your answer goes here** Max 50 words

The differences of the stock do seem to look like white noise. There does not appear to be any trend affecting the data as it has random variability and no correlation or pattern can be identified.

------------------------------------------------------------------------

-   3.2.6 What about the original series `Close`? **(0.45 points)**

------------------------------------------------------------------------

**Your answer goes here** Max 50 words

The original variable Close does not appear to be white noise since there is a clear correlation between the variable as the lags. As there are many weeks, a lot of lag plots are needed in order to observe trends. More than 100 lags are needed to determine if there is seasonality of a cyclic behavior every 68 lags.

------------------------------------------------------------------------
