---
title: "asgmt1_tsgraphs"
format: html
editor: visual
params:
  print_sol: false
toc: true
toc-location: left
toc-depth: 6
self-contained: true
---

# Libraries

```{r}
library(fpp3)
```

# Instructions

-   This notebook contains a series of exercises **to be solved individually by each student**.

-   When answering the questions please **stick to the questions asked and respect the limit to the number of words** (use an online word counter or your text processor of choice).

-   **Answering more than what is asked for in the question will not provide additional points**. More often than not, it actually leads to a worse grade since the additional info provided usually shows a lack of understanding of some concepts on the student's part.

-   **Before delivering the assignment** **make sure you are delivering executable code**. To do this (dedicated video on the appendix RStudio Basics)

    1.  Delete all variables in your environment.
    2.  Restart your R Session.
    3.  Click on Run -\> Run all

    -   **IMPORTANT:** if the code you deliver is not executable from beginning to end, you will be somewhat penalized in your assignment (depending on the severity of the issue). So please bear this in mind. At university level the least expected is that you deliver executable code.

# 1. (3.3 points)

The PBS dataset included in fpp3 contains Monthly Medicare Australia prescription data. Run `?PBS` on the console for further info.

We would like to focus on the prescriptions with ATC (Anatomical Therapeutic Chemical Index level 2) equal to H02. This group corresponds to corticosteroids for systemic use.

```{r}
PBS_h02 <- PBS %>%
  filter(ATC2 == "H02") %>%
  select(ATC2, Month, Cost, everything()) %>%
  arrange(Month)
print(PBS_h02)
```

1.  As you can see, after filtering for `ATC2 == H02` there are 4 entries per month corresponding to different combinations of the columns Concession and Type. We would like to add the Cost associated to those 4 entries for every month, to obtain a time series of the total cost per month. Use `index_by()` and `summarise()` to get the total cost per month **(1 point)**

```{r}
PBS_h02_m<- PBS_h02 %>%
  index_by(month = yearmonth(Month)) %>%
  summarise(
    total_cost = sum(Cost)
  )

PBS_h02_m
```

2.  Create and interpret a time-plot with sufficient resolution to visually identify the seasonality **(0.8 points)**

```{r}
PBS_h02_m %>%
  autoplot(total_cost, period = "year") + 
 scale_x_yearquarter(date_breaks = "1 year",
                      minor_breaks = "1 year") +
  theme(axis.text.x = element_text(angle = 90))
  
  
```

------------------------------------------------------------------------

This graph shows a strong upward trend with a seasonality component: the second month of each year starts at the year's lowest total cost yet increases towards last months, the cost goes to the highest of the year only to drop back once again in February of the following year.

------------------------------------------------------------------------

3.  Create and interpret a seasonal plot and a seasonal subseries plots to identify the evolution of the seasonal component. **(0.8 points)**

```{r}
PBS_h02_m %>%
  gg_season(total_cost, labels = "both") + 
  labs(y = "$ (millions)",
       title = "Seasonal plot: Cost on Prescriptions with H02, Autralia Medicare")
##
PBS_h02_m %>%
  gg_subseries(total_cost) +
  labs(
    y = "$ (millions)",
    title = "Seasonal Subseries: Cost on Prescriptions with H02, Autralia Medicare",
  )
```

------------------------------------------------------------------------

These graphs make the seasonal component more clear as it also shows large jumps in costs each year. The costs are at its highest in the end of December and beginning of January which then drop in February just to rise through each month towards December (has the highest costs).

------------------------------------------------------------------------

4.  Create and interpret ACF plots and lag plots to identify the seasonality **(0.8 points)**

```{r}
recent_cost <- PBS_h02_m %>%
  select(month, total_cost)

for (i in seq(1, 12)) {
  lag_name = paste0("Cost_lag", as.character(i))
  recent_cost[[lag_name]] = lag(recent_cost[["total_cost"]], i)
}

recent_cost


# Lag Plot
recent_cost %>%
  gg_lag(y = total_cost, geom = "point", lags = 1:12)

##
n_lag = 4
lag_name = paste0("Cost_lag", n_lag)

recent_cost %>% 
  autoplot() +
  scale_x_yearquarter(breaks = "1 year",
                      minor_breaks = "1 year") +
  geom_line(aes_string(x = "month", y = lag_name), 
            color = "blue",
            linetype = "dashed")+
  theme(axis.text.x = element_text(angle = 90))

# ACF Plot 
recent_cost %>%
  ACF(lag_max = 24) %>%
  autoplot()
```

------------------------------------------------------------------------

The graphs shown depict a seasonal trend; as shown in ACF autoplot and lagplots, the autocrrelation values of variable and lag are high at multiples of the seasonal period (yearly).

------------------------------------------------------------------------

# 2. (3.3 points)

Use the following graph functions: autoplot(), gg_season(), gg_subseries(), gg_lag(), ACF() and explore features of the time series Total Private from the dataset us_employment (loaded with fpp3) (3.3 points)

```{r}
total_private <- us_employment %>%
  filter(Title == "Total Private")

total_private
```

-   2.1 Generate a timeplot that has major ticks every ten years and minor ticks every year **(1.1 points)**

```{r}
total_private %>%
  autoplot(Employed, period = "year") + 
 scale_x_yearquarter(date_breaks = "10 years",
                      minor_breaks = "1 year") +
  theme(axis.text.x = element_text(angle = 90))
```

-   2.2 Use `gg_season()` and `gg_subseries()` to examine the evolution of the seasonal components over time (period of 1 year). That is, generate the graphs and interpret them **(1.1 points)**

```{r}
#gg season
total_private %>%
  gg_season(Employed, Period= "1 year", labels = "both") + 
  labs(y = "People Employed",
       title = "Seasonal plot: US Employment ")

# gg suberies
total_private %>%
  gg_subseries(Employed, Period= "1 year") +
  labs(
    y = "People Employed",
    title = "Seasonal Subseries: US Employment",
  )
```

------------------------------------------------------------------------

The graphs seem to show a strong upward trend, it also shows strong (yearly) seasonal components. These plots show fixed fluctuations with constant length. The data however seems to increase per year and not per month as monthly data remains constant. 

------------------------------------------------------------------------

-   2.3 Use `gg_lag()` and `ACF()` to examine the autocorrelation of the series. Again, generate the graphs and interpret them **(1.1 points)**

```{r}
recent_employment <- total_private %>%
  select(Month, Employed)
recent_employment

for (i in seq(1, 12)) {
  lag_name = paste0("employment_lag", as.character(i))
  recent_employment[[lag_name]] = lag(recent_employment[["Employed"]], i)
}

recent_employment


# Lag Plot
recent_employment %>%
  gg_lag(y = Employed, geom = "point", lags = 1:12)

##
n_lag = 4
lag_name = paste0("employment_lag", n_lag)

recent_employment %>% 
  autoplot() +
  scale_x_yearquarter(breaks = "1 year",
                      minor_breaks = "1 year") +
  geom_line(aes_string(x = "Month", y = lag_name), 
            color = "red",
            linetype = "dashed")+
  theme(axis.text.x = element_text(angle = 90))

# ACF Plot 
recent_employment %>%
  ACF(lag_max = 24) %>%
  autoplot()
```

------------------------------------------------------------------------

The plots depicted show an extremely high and positive autocorrelation. This can be seen from the lag plotâ€™s constant values throughout each month that are clustered around the line that shows the true/original value. This is also shown through the constant and positive lines printed in the ACF plot. 

------------------------------------------------------------------------

# 3. Stock prices (3.4/10 points)

The GAFA stock prices dataset in the ffp3 package contains historical stock prices from 2014-2018 for Google, Amazon, Facebook and Apple. All prices are in \$USD

## 3.1 Use `group_by()` in combination with `filter()` and `max()` to finde what days correspond to the peak closing price for each of the four stocks in the dataset `gafa_stock` (**0.5 points**)

```{r}
persymbol<- gafa_stock%>%
  group_by(Symbol)%>%
  filter(Close == max(Close))

persymbol

```

## 3.2 Amazon Stock Prices

The following code computes the daily changes in Amazon closing stock prices from 2018 onwards:

```{r}
damzn <- gafa_stock %>%
  filter(Symbol == "AMZN", year(Date) >= 2018) %>%
  mutate(trading_day = row_number()) %>%
  update_tsibble(index = trading_day, regular = TRUE) %>%
  mutate(diff = difference(Close))
damzn
```

-   3.2.1 Why does the code above re-index the tsibble? Hint: run `?update_tsibble()` on the console to access the documentation and read about the argument regular (**0.5 points**)

------------------------------------------------------------------------

In the code we calculate the transformations of the variable "trading_day" with new modifications; therefore that variable uniquely determines regular time indices that need to update after the mutate function.

------------------------------------------------------------------------

-   3.2.2 Use the function `lag()` to compute an additional column `diff2` that should be equal to the column `diff`. Hint: you need to compute the first lag of the variable Close to do this. (**0.5 points**)

```{r}
diff_damzn <- damzn %>%
  select(Date, diff)

for (i in 2) {
  lag_name = paste("diff2")
  diff_damzn[[lag_name]] = lag(diff_damzn[["diff"]], i)
}

diff_damzn
```

-   3.2.3 Create a time plot of the closing prices and a time plot of the differences. These plots must have major ticks every 20 trading days and minor ticks every 10 trading days (**0.5 points**)

```{r}
# time plot differences
diff_damzn %>%
  autoplot(diff, period = "day") + 
 scale_x_yearquarter(date_breaks = "20 day",
                      minor_breaks = "10 day") +
  theme(axis.text.x = element_text(angle = 90))

# time plot of closing prices
closingamzn <-gafa_stock %>%
  filter(Symbol == "AMZN", year(Date) >= 2018) %>%
  mutate(trading_day = row_number()) 

closingamzn %>%
  autoplot(Close, period = "day") + 
 scale_x_yearquarter(date_breaks = "20 day",
                      minor_breaks = "10 day") +
  theme(axis.text.x = element_text(angle = 90))
  
```

-   3.2.4 Create the correlogram of the closing prices and of the differences in prices using the ACF() and autoplot() functions. Depict 100 lags (look at the argument lag_max). **(0.5 points)**

```{r}
# closing prices 
closingamzn %>%
  ACF(lag_max = 100)%>%
  autoplot()

# differences 
diff_damzn %>%
  ACF(lag_max = 100) %>%
  autoplot()
```

-   3.2.5 Do the differences in the stock look like white noise? **(0.45 points)**.

------------------------------------------------------------------------

No, the ACF plots shows that there is indeed an autocorrelation as there is a clear trend and a negative slope that depicts a decreasing ACF across time with the strongest correlation at lag 1. This plots depicts a AR with a geometric decay. 


------------------------------------------------------------------------

-   3.2.6 What about the original series `Close`? **(0.45 points)**

------------------------------------------------------------------------

The original series shows a similar plot with a faster AR geometric decay. This is because the ACF values show a more uniform decay per lap with no vraiation as the plot for differences has. There is, once again, a trong autocorrelation which makes it not a white noice ACF. 

------------------------------------------------------------------------
