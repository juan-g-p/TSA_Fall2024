---
title: "asgmt1_tsgraphs"
format: html
editor: visual
params:
  print_sol: false
toc: true
toc-location: left
toc-depth: 6
self-contained: true
---

# Libraries

```{r}
library(fpp3)
```

# Instructions

-   This notebook contains a series of exercises **to be solved individually by each student**.

-   When answering the questions please **stick to the questions asked and respect the limit to the number of words** (use an online word counter or your text processor of choice).

-   **Answering more than what is asked for in the question will not provide additional points**. More often than not, it actually leads to a worse grade since the additional info provided usually shows a lack of understanding of some concepts on the student's part.

-   **Before delivering the assignment** **make sure you are delivering executable code**. To do this (dedicated video on the appendix RStudio Basics)

    1.  Delete all variables in your environment.
    2.  Restart your R Session.
    3.  Click on Run -\> Run all

    -   **IMPORTANT:** if the code you deliver is not executable from beginning to end, you will be somewhat penalized in your assignment (depending on the severity of the issue). So please bear this in mind. At university level the least expected is that you deliver executable code.

# 1. (3.3 points)

The PBS dataset included in fpp3 contains Monthly Medicare Australia prescription data. Run `?PBS` on the console for further info.

We would like to focus on the prescriptions with ATC (Anatomical Therapeutic Chemical Index level 2) equal to H02. This group corresponds to corticosteroids for systemic use.

```{r}
PBS_h02 <- PBS %>%
  filter(ATC2 == "H02") %>%
  select(ATC2, Month, Cost, everything()) %>%
  arrange(Month)

View(PBS_h02)
```

1.  As you can see, after filtering for `ATC2 == H02` there are 4 entries per month corresponding to different combinations of the columns Concession and Type. We would like to add the Cost associated to those 4 entries for every month, to obtain a time series of the total cost per month. Use `index_by()` and `summarise()` to get the total cost per month **(1 point)**

```{r}
costs_total <- PBS_h02 %>%
  index_by(month = yearmonth(Month)) %>%
  summarise(
    costs_sum = sum(Cost)
  )

print(costs_total)
```

2.  Create and interpret a time-plot with sufficient resolution to visually identify the seasonality **(0.8 points)**

```{r}
autoplot(costs_total, costs_sum) +
  labs(y = "$ (millions)",
       title = "Australian antidiabetic drug sales seasonality and trend") +
  scale_x_yearmonth(breaks = "1 year") +
  theme(axis.text.x = element_text(angle = 90))
```

------------------------------------------------------------------------

The time-plot clearly shows that there is seasonality because there are "peaks" in the curve at the same time of the year for every year. This shows that the costs of the drugs increase at the last months and that this is a recurrent scenario every year.

------------------------------------------------------------------------

3.  Create and interpret a seasonal plot and a seasonal subseries plots to identify the evolution of the seasonal component. **(0.8 points)**

```{r}
# Seasonal plot
costs_total %>%
  gg_season(costs_sum) +
  labs(y = "$ (millions)",
       title = "Seasonal plot: Antidiabetic drug sales")

# Subseries plot
costs_total %>%
  gg_subseries(costs_sum)+
  labs(y = "$ (millions)",
       title = "Australian antidiabetic drug sales")



```

------------------------------------------------------------------------

The seasonal plot shows again that the costs of drugs rise from February to December and go down during January every year to their lowest point. The subseries plot shows that apart from having seasonality, costs overall have increased during years.

------------------------------------------------------------------------

4.  Create and interpret ACF plots and lag plots to identify the seasoanlity **(0.8 points)**

```{r}
# ACF plot
costs_total %>% ACF() %>% autoplot()

# Lag plot
costs_total %>%
  gg_lag(y = costs_sum, geom = "point", lags = 1:12)
```

------------------------------------------------------------------------

Seasonality can be observed in both the ACF plot and the lag plots as the bars of the ACF plot follow a pattern every year. Regarding the lag plot, it shows that there is a positive linear trend and that there are some months that are more correlated to each other.

------------------------------------------------------------------------

# 2. (3.3 points)

Use the following graph functions: autoplot(), gg_season(), gg_subseries(), gg_lag(), ACF() and explore features of the time series Total Private from the dataset us_employment (loaded with fpp3) (3.3 points)

```{r}
total_private <- us_employment %>%
  filter(Title == "Total Private")

total_private
```

-   2.1 Generate a timeplot that has major ticks every ten years and minor ticks every year **(1.1 points)**

```{r}
total_private %>%
  autoplot(Employed) + 
  scale_x_yearquarter(date_breaks = "10 year",
                      minor_breaks = "1 year") +
  theme(axis.text.x = element_text(angle = 90))

```

-   2.2 Use `gg_season()` and `gg_subseries()` to examine the evolution of the seasonal components over time (period of 1 year). That is, generate the graphs and interpret them **(1.1 points)**

```{r}
# Seasonal plot
total_private %>%
  gg_season(Employed) +
  labs(title = "Total Private Employees")

# Subseries plot
total_private %>%
  gg_subseries(Employed)+
  labs(title = "Total Private Employees")
```

------------------------------------------------------------------------

Both graphs show that the number of employees grows by just little throughout the months of a year. Therefore, every year there are more employees overall, which has led to a large increase in the employees from 1958 to 2018.

------------------------------------------------------------------------

-   2.3 Use `gg_lag()` and `ACF()` to examine the autocorrelation of the series. Again, generate the graphs and interpret them **(1.1 points)**

```{r}
# ACF plot
total_private %>% ACF(Employed) %>% autoplot()

# Lag plot
total_private %>%
  gg_lag(y = Employed, geom='point', lags=1:12)
```

------------------------------------------------------------------------

The ACF plot shows that there is a clear trend of the growth in number of employees in the company because the bars' heights decrease as there are more lags. Also, it shows that there is a high positive autocorrelation between the data as the data is clustered in the diagonal.

------------------------------------------------------------------------

# 3. Stock prices (3.4/10 points)

The GAFA stock prices dataset in the ffp3 package contains historical stock prices from 2014-2018 for Google, Amazon, Facebook and Apple. All prices are in \$USD

## 3.1 Use `group_by()` in combination with `filter()` and `max()` to find what days correspond to the peak closing price for each of the four stocks in the dataset `gafa_stock` (**0.5 points**)

```{r}
gafa_stock %>% group_by(Symbol) %>% filter(Close == max(Close))
```

## 3.2 Amazon Stock Prices

The following code computes the daily changes in Amazon closing stock prices from 2018 onwards:

```{r}
damzn <- gafa_stock %>%
  filter(Symbol == "AMZN", year(Date) >= 2018) %>%
  mutate(trading_day = row_number()) %>%
  update_tsibble(index = trading_day, regular = TRUE) %>%
  mutate(diff = difference(Close))

damzn
```

-   3.2.1 Why does the code above re-index the tsibble? Hint: run `?update_tsibble()` on the console to access the documentation and read about the argument regular (**0.5 points**)

------------------------------------------------------------------------

Filtering for the "AMZ" symbol and using Date as the index, results in different intervals for each row, which is not useful. Re-indexing allows us to have the same intervals.Â 

------------------------------------------------------------------------

-   3.2.2 Use the function `lag()` to compute an additional column `diff2` that should be equal to the column `diff`. Hint: you need to compute the first lag of the variable Close to do this. (**0.5 points**)

```{r}
damzn[[paste0("diff2")]] = lag(damzn$diff, 1)
View(damzn)
```

-   3.2.3 Create a time plot of the closing prices and a time plot of the differences. These plots must have major ticks every 20 trading days and minor ticks every 10 trading days (**0.5 points**)

```{r}
# Time Plot Closing prices 
damzn %>%
  autoplot(Close) + 
  scale_x_yearweek(date_breaks = "20 days",
                      minor_breaks = "10 days") +
  theme(axis.text.x = element_text(angle = 90))


# Time Plot Diff 
damzn %>%
  autoplot(diff) + 
  scale_x_yearweek(date_breaks = "20 days",
                      minor_breaks = "10 days") +
  theme(axis.text.x = element_text(angle = 90))


# Time Plot Diff2
damzn %>%
  autoplot(diff2) + 
  scale_x_yearweek(date_breaks = "20 days",
                      minor_breaks = "10 days") +
  theme(axis.text.x = element_text(angle = 90))
```

-   3.2.4 Create the correlogram of the closing prices and of the differences in prices using the ACF() and autoplot() functions. Depict 100 lags (look at the argument lag_max). **(0.5 points)**

```{r}
# Closing prices
damzn %>%
  ACF(Close, lag_max = 100) %>%
  autoplot()

# Differeces in prices 
damzn %>%
  ACF(diff, lag_max = 100) %>%
  autoplot()


```

-   3.2.5 Do the differences in the stock look like white noise? **(0.45 points)**.

------------------------------------------------------------------------

The differences in the stock look like white noise because autocorrelation is very close to zero and there are just few (2 spikes) that go over the boundaries, which is less than 5%. Moreover, there are lines that are very close to zero, supporting the idea that there is no correlation between the observations of the series.

------------------------------------------------------------------------

-   3.2.6 What about the original series `Close`? **(0.45 points)**

------------------------------------------------------------------------

The original series Close does not look like white noise as most spikes go over the blue boundaries and they are significantly larger than zero, showing that there is a strong correlation between the observations of the series. In short, the observations do not follow a random pattern.

------------------------------------------------------------------------
