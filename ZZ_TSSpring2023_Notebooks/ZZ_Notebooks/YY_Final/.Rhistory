col3 = c(1, 2, 1, 2, 3)
)
# Count the number of unique combinations of col1 and col2 values:
n_distinct <- df_toy %>%
distinct(col1, col2) %>%
nrow()
# Number of unique combinations of col1 and col2
n_distinct
# YOUR CODE GOES HERE
colnames(usgas_y_m) # y_m is index and monthly_gas is data
n_distinct <- usgas_y_m %>%
distinct(process, state) %>%
nrow()
n_distinct
# 250 total
# Your code goes here
# 1.
mutated_usgas_y_m <- usgas_y_m %>% mutate(yearcol = year(y_m))
# 2.
usgas_y <- mutated_usgas_y_m %>% group_by(state, process, yearcol) %>% summarize (totalgas = sum(monthly_gas) )
# 3.
new <- usgas_y %>%  filter(process == ' Vehicle Fuel Consumption' ) %>% group_by(yearcol) %>%
summarize(
maxconsumpion = max(totalgas))
new
new
usgas_y
# Your code goes here
colnames(usgas_y_m)
cali_fuel_y_m <- usgas_y_m %>% filter(state == 'California' & process == 'Vehicle Fuel Consumption')
cali_fuel_y_m %>% autoplot(monthly_gas) + scale_x_yearquarter (date_breaks = "1 year",
minor_breaks =  "1 year") +
theme(axis.text.x = element_text(angle = 90))
# Your code goes here
lambda <- cali_fuel_y_m %>%
features(monthly_gas, features = guerrero) %>%
pull(lambda_guerrero)
lambda
# looking at our graph, it seems that there is a slight bit of multiplicativity, becasue the variation at higher levels of  monthly_gas is a bit higher than at the lower levels of monthly_gas. -> transformation might be useful.
# our lambda is very close to 0, which means that doing a box-cox transformation would be equal to doing a  a logarithmic transformation, which is why we would do a logarithmic
# Your code goes here
#CREATE SET OF TRANINING DATASETS
# 156 x 4
init = round(nrow(cali_fuel_y_m)*0.6)
training_sets <- cali_fuel_y_m %>%
stretch_tsibble(.init = init, .step = 3)
# Your code goes here
# Number of training datasets generated
training_sets %>% pull(.id) %>% max()
# 21
# Your code goes here
# smallest:
smallest = round(nrow(cali_fuel_y_m)*0.6)
cat('the smallest training dataset hast' , smallest, 'values')
# biggest
biggest = smallest + 3* 20 # bc we created 21 sets
cat('the biggest training dataset hast' , biggest, 'values')
# Your code goes here
# # fitting models
fit = training_sets %>% model(
# 1. `decomposition_model` applying an STL decomposition and a log transformation. Use a
#     * drift model for the seasonally adjusted component
#     * a seas. na誰ve model for the seasonal component
decomposition_model1 = decomposition_model(
STL(log(monthly_gas)),
RW(season_adjust ~ drift()),
SNAIVE(season_year)
),
# 2. `decomposition_model` applying an STL decomposition and no transformation. Use a
#     * drift model for the seasonally adjusted component
#     * a seas. na誰ve model for the seasonal component.
decomposition_model2 = decomposition_model(
STL(monthly_gas),
RW(season_adjust ~ drift()),
SNAIVE(season_year)),
# 3. `decomposition_model` applyting an STL decomposition and a log transformation. Use a:
#     * SES (Simple Exp. Smoothing) model for the seasonally adjusted component
#     * a seas. na誰ve model for the seasonal component.
decomposition_model3 = decomposition_model(
STL(log(monthly_gas)),
ETS(season_adjust ~ error("A") + trend("N") + season("N")),
SNAIVE(season_year)),
# 4. `decomposition_model` applyting an STL decomposition with no transformation. Use a:
#     * SES (Simple Exp. Smoothing) model for the seasonally adjusted component
#     * a seas. na誰ve model for the seasonal component.
decomposition_model4 = decomposition_model(
STL(monthly_gas),
ETS(season_adjust ~ error("A") + trend("N") + season("N")),
SNAIVE(season_year)) ,
# 5. An SES (Simple) exponential smoothing model
SES_model =  ETS(monthly_gas ~ error("A") + trend("N") + season("N")),
# 6. A Naive model
Naive_model = NAIVE(monthly_gas),
)
#
#
#
# After having fitted the models, perform **one year ahead forecasts**.
forecasts <- fit %>% forecast(h = 12) # 12 because we have monthly data and 1 months is 1 y
# Subsequently, examine which model:
# Has best forecasting performance in terms of RMSE. Compute the average RMSE over all the forecast horizons.
summary <- forecasts %>%
accuracy(cali_fuel_y_m) %>%
select(.model, .type, RMSE) %>%
arrange(RMSE)
summary
)
usgas_y_m <-
read_xlsx(file.choose()) %>%
mutate(
y_m = yearmonth(date)
) %>%
as_tsibble(
key=c(state, process),
index = y_m
) %>%
select(process, state, y_m, monthly_gas)
colnames(usgas_y_m)
df_toy <- tibble(
col1 = c("a", "b", "a", "b", "a"),
col2 = c("x", "y", "x", "y", "z"),
col3 = c(1, 2, 1, 2, 3)
)
# Count the number of unique combinations of col1 and col2 values:
n_distinct <- df_toy %>%
distinct(col1, col2) %>%
nrow()
# Number of unique combinations of col1 and col2
n_distinct
# YOUR CODE GOES HERE
n_distinct <- usgas_y_m %>%
distinct(process, state) %>%
nrow()
n_distinct
# Your code goes here
ex2 <- usgas_y_m %>%
index_by(year = year(y_m))
usgas_y <- ex2 %>%
group_by(process, state, year) %>%
summarize(total_gas = sum(monthly_gas))
max_year <- usgas_y %>%
filter(process == "Vehicle Fuel Consumption") %>%
index_by(year) %>%
filter(total_gas== max(total_gas))
max_year
usgas_y_m
usgas_y_m %>%
index_by(year = year(y_m))
# Your code goes here
cali_fuel_y_m <- usgas_y_m %>%
filter(state == "California" & process == "Vehicle Fuel Consumption")
cali_fuel_y_m %>% autoplot(monthly_gas) +
scale_x_yearmonth(date_breaks = "1 year",
minor_breaks = "1 year") +
# Flip x-labels by 90 degrees
theme(axis.text.x = element_text(angle = 90))
# Your code goes here
lambda <- cali_fuel_y_m %>%
features(monthly_gas, features = guerrero) %>%
pull(lambda_guerrero)
lambda
cali_fuel_y_m %>% autoplot(log(monthly_gas)) +
scale_x_yearmonth(date_breaks = "1 year",
minor_breaks = "1 year") +
# Flip x-labels by 90 degrees
theme(axis.text.x = element_text(angle = 90))
cali_fuel_y_m
# Your code goes here
cali_fuel_y_m_cv <- cali_fuel_y_m %>%
stretch_tsibble(.init = 94, .step = 3)
cali_fuel_y_m_cv
# Your code goes here
cali_fuel_y_m_cv %>% pull(.id) %>% max()
# Your code goes here
size_check <- cali_fuel_y_m_cv %>%
group_by(.id) %>%
count()
min(size_check$n)
max(size_check$n)
# Your code goes here
# fit the models
fit <- cali_fuel_y_m_cv %>%
model(
decomp_log = decomposition_model(
STL(log(monthly_gas)),
RW(season_adjust ~ drift()),
SNAIVE(season_year)
),
decomp = decomposition_model(
STL(monthly_gas),
RW(season_adjust ~ drift()),
SNAIVE(season_year)
),
decomp_log_ses = decomposition_model(
STL(log(monthly_gas)),
ETS(season_adjust ~ error("A") + trend("N") + season("N")),
SNAIVE(season_year)
),
decomp_ses = decomposition_model(
STL(monthly_gas),
ETS(season_adjust ~ error("A") + trend("N") + season("N")),
SNAIVE(season_year)
),
`Naive` = NAIVE(monthly_gas),
SES = ETS(monthly_gas ~ error("A") + trend("N") + season("N"))
)
fit
# forecasts
forecasts <- fit %>% forecast(h = "1 year")
forecasts
summary_ts <- forecasts %>%
accuracy(cali_fuel_y_m) %>%
select(.model, .type, RMSE, MAE, MAPE) %>%
arrange(RMSE)
summary_ts
# Your code goes here
fit_all <- cali_fuel_y_m %>%
model(
decomp_ses = decomposition_model(
STL(monthly_gas),
ETS(season_adjust ~ error("A") + trend("N") + season("N")),
SNAIVE(season_year)
)
)
fit_all
summary_res <- fit_all %>%
accuracy() %>%
select(.model, .type, RMSE, MAE, MAPE)
summary_res
fit_all %>%
gg_tsresiduals()
usgas_y_m <-
read_xlsx(file.choose()) %>%
mutate(
y_m = yearmonth(date)
) %>%
as_tsibble(
key=c(state, process),
index = y_m
) %>%
select(process, state, y_m, monthly_gas)
colnames(usgas_y_m)
# Ensure `y_m` is a year-month object and then extract the year
usgas_y_m <- usgas_y_m %>%
mutate(year = year(ym(y_m)))
# Compute the total gas consumed by each state, for each process, each year
usgas_y <- usgas_y_m %>% as_tibble() %>%
group_by(year, state, process) %>%
summarise(total_gas = sum(monthly_gas))
usgas_y_final <- usgas_y %>%
filter(process == "Vehicle Fuel Consumption") %>%
group_by(year) %>%
slice_max(total_gas) %>%
ungroup()
# Select only the desired columns
usgas_y_final_selected <- usgas_y_final %>%
select(state, total_gas, year)
usgas_y_final_selected
cali_fuel_y_m <- usgas_y_m %>%
filter(state== "California" & process == "Vehicle Fuel Consumption")
cali_fuel_y_m %>%
autoplot(monthly_gas) + labs(y = "Monthly gas Gas consumtion ,California Vehicle Fuel Consumption ") +
# Adjust the x-grid
scale_x_yearmonth(date_breaks = "1 year",
date_minor_breaks = "1 year") +
# Flip x-labels by 90 degrees
theme(axis.text.x = element_text(angle = 90))
lambda <- cali_fuel_y_m %>%
features(monthly_gas, features = guerrero) %>%
pull(lambda_guerrero)
lambda
cali_fuel_y_m %>% autoplot(box_cox(monthly_gas, lambda)) # check the box cox tranformation
cali_fuel_y_m %>% autoplot(log(monthly_gas)) # check both transfomations visually
# first create the training datasets
nobs <- cali_fuel_y_m %>% nrow()
nobs
split_row = as.integer(nobs * 0.6)
cali_fuel_y_m_cv <- cali_fuel_y_m %>%
stretch_tsibble(.init = 94, .step = 3)
# Inspect result
cali_fuel_y_m_cv
cali_fuel_y_m_cv %>% pull(.id) %>% max # we have generated 21 training datasets
# Talbe detailing dimensions of each training dataset
cali_fuel_y_m_cv %>%
as_tibble() %>% # Cast to a tibble to be able to do away with time index
group_by(.id) %>%
summarize(
size = n()
)
# As we can see the smallest dataset starts at 94 observations
# And the dataset with the .id 21 which is the biggest has 154 obsevations
fit_cv <- cali_fuel_y_m_cv %>%
model(
decomp_log = decomposition_model(
# Specify decomposition scheme to be used
STL(log(monthly_gas)),
# Specify model for the seasonally adjusted component
RW(season_adjust ~ drift()),
# Specify model for the seasonal component (unnecessary since SNAIVE is default)
SNAIVE(season_year)
),
decomp_log_ses = decomposition_model(
# Specify decomposition scheme to be used
STL(log(monthly_gas)),
# Specify model for the seasonally adjusted component
SNAIVE(season_year),
SES = ETS(season_adjust ~ error("A") + trend("N") + season("N")),
# Specify model for the seasonal component (unnecessary since SNAIVE is default)
SNAIVE(season_year)
),
decomp = decomposition_model(
# Specify decomposition scheme to be used
STL(monthly_gas),
# Specify model for the seasonally adjusted component
RW(season_adjust ~ drift()),
# Specify model for the seasonal component (unnecessary since SNAIVE is default)
SNAIVE(season_year)
),
decomp_no_trans_ses = decomposition_model(
# Specify decomposition scheme to be used
STL(monthly_gas),
# Specify model for the seasonally adjusted component
SES = ETS(season_adjust ~ error("A") + trend("N") + season("N")),
# Specify model for the seasonal component (unnecessary since SNAIVE is default)
SNAIVE(season_year)
))
fit_cv
cali_fuel_y_m_cv_fc <- fit_cv %>%
forecast(h = 12) # 12 months ahead forecast that is one year
cali_fuel_y_m_cv_fc
# this step is unasscary
cali_fuel_y_m_cv_fc <- cali_fuel_y_m_cv_fc %>%
group_by(.id, .model) %>%
mutate(h = row_number()) %>%
ungroup() %>%
as_fable(response = "monthly_gas", distribution = monthly_gas)
cali_fuel_y_m_cv_fc
cali_fuel_y_m_cv_fc %>%
accuracy(cali_fuel_y_m) %>%
arrange(RMSE) %>%
select(.model, .type, RMSE)
fit <- cali_fuel_y_m %>%
model(
decomp_ses = decomposition_model(
# Specify decomposition scheme to be used
STL(monthly_gas),
# Specify model for the seasonally adjusted component
ETS(season_adjust ~ error("A") + trend("N") + season("N")),
# Specify model for the seasonal component (unnecessary since SNAIVE is default)
SNAIVE(season_year)
)
)
fit %>% gg_tsresiduals()
usgas_y_m <-
read_xlsx(file.choose()) %>%
mutate(
y_m = yearmonth(date)
) %>%
as_tsibble(
key=c(state, process),
index = y_m
) %>%
select(process, state, y_m, monthly_gas)
colnames(usgas_y_m)
usgas_y_m <-
read_xlsx(file.choose()) %>%
mutate(
y_m = yearmonth(date)
) %>%
as_tsibble(
key=c(state, process),
index = y_m
) %>%
select(process, state, y_m, monthly_gas)
colnames(usgas_y_m)
df_toy <- tibble(
col1 = c("a", "b", "a", "b", "a"),
col2 = c("x", "y", "x", "y", "z"),
col3 = c(1, 2, 1, 2, 3)
)
# Count the number of unique combinations of col1 and col2 values:
n_distinct <- df_toy %>%
distinct(col1, col2) %>%
nrow()
# Number of unique combinations of col1 and col2
n_distinct
# YOUR CODE GOES HERE
num_time_series <- usgas_y_m %>%
distinct(state, process) %>%
nrow()
num_time_series
# Your code goes here
usgas_y <- usgas_y_m %>%
mutate(year = year(y_m)) %>%
group_by(state, process, year) %>%
summarize(total_gas = sum(monthly_gas, na.rm = TRUE))
usgas_vehicle <- usgas_y %>%
filter(process == "Vehicle Fuel Consumption") %>%
group_by(year) %>%
slice(which.max(total_gas))
# below shows by state
usgas_vehicle_st <- usgas_y %>%
filter(process == "Vehicle Fuel Consumption") %>%
group_by(state) %>%
slice(which.max(total_gas))
usgas_vehicle_st
usgas_vehicle_st
usgas_vehicle_st
# Your code goes here
# Extract series
cali_fuel_y_m <- usgas_y_m %>% select(process, state, y_m, monthly_gas) %>% filter(process == "Vehicle Fuel Consumption")%>%
summarize(total_gas = sum(monthly_gas))
cali_fuel_y_m %>% autoplot()  +
scale_x_yearmonth(date_breaks = "1 year",
minor_breaks = "3 months") +
theme(axis.text.x = element_text(angle = 90))
# Your code goes here
lambda <- cali_fuel_y_m %>%
features(total_gas, features = guerrero) %>%
pull(lambda_guerrero)
lambda
# with this lambda value a transformation could be useful
# Your code goes here
n_obs <- nrow(cali_fuel_y_m)
n_init <- round(n_obs * 0.6)
cali_fuel_cv <- cali_fuel_y_m %>%
stretch_tsibble(.init = n_init, .step = 3)
cali_fuel_cv
# Your code goes here
cali_fuel_cv %>% pull(.id) %>% max
# 21 datasets
# Your code goes here
cali_fuel_cv %>% pull(.id) %>% max
# 21 datasets
# Your code goes here
# dimensions
dim(cali_fuel_cv)
# smallest size observation
smallest_size <- cali_fuel_cv %>%
filter(.id == 1) %>%
summarise(n = n()) %>%
pull(n)
smallest_size
# biggest size observation
biggest_size <- cali_fuel_cv %>%
filter(.id == max(.id)) %>%
summarise(n = n()) %>%
pull(n)
# Your code goes here
# dimensions
dim(cali_fuel_cv)
# smallest size observation
smallest_size <- cali_fuel_cv %>%
filter(.id == 1) %>%
summarise(n = n()) %>%
pull(n)
smallest_size
# biggest size observation
biggest_size <- cali_fuel_cv %>%
filter(.id == max(.id)) %>%
summarise(n = n()) %>%
pull(n)
smallest_size
biggest_size
# Your code goes here
fit_dcmp <- cali_fuel_cv %>%
model(
decomp_log = decomposition_model(
STL(log(total_gas)),
RW(season_adjust ~ drift()),
SNAIVE(season_year)
),
decomp = decomposition_model(
STL(total_gas),
RW(season_adjust ~ drift()),
SNAIVE(season_year)
),
decomp_log_ses = decomposition_model(
STL(log(total_gas)),
ETS(season_adjust ~ error("A") + trend("N") + season("N")),
SNAIVE(season_year)
),
decomp_box = decomposition_model(
STL(total_gas),
ETS(season_adjust ~ error("A") + trend("N") + season("N")),
SNAIVE(season_year)
),
naive = NAIVE(total_gas),
SES = ETS(total_gas ~ error("A") + trend("N") + season("N"))
)
fit_dcmp
summary_tr <- fit_dcmp %>%
accuracy() %>%
select(.model, .type, MAE, RMSE, MAPE, MASE, RMSSE) %>%
arrange(MASE) # Order from smallest to highest MASE
summary_tr
RMSE_av <- summary_tr %>%
group_by(.model) %>%
summarize(av = mean(RMSE, na.rm = TRUE))
RMSE_av
summary_tr <- fit_dcmp %>%
accuracy() %>%
select(.model, .type, MAE, RMSE, MAPE, MASE, RMSSE) %>%
arrange(MASE) # Order from smallest to highest MASE
summary_tr %>%
group_by(.model) %>%
summarize(Average_RMSE = mean(RMSE, na.rm = TRUE),
Average_MASE = mean(MASE, na.rm = TRUE))
# Your code goes here
fit_ses <- cali_fuel_y_m %>%
model(ETS(total_gas ~ error("A") + trend("N") + season("N")))
fit_ses %>% gg_tsresiduals()
